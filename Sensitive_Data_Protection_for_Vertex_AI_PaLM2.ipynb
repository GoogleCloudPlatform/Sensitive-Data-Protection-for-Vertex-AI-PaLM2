{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGzTHJJUCPY"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK1Q5ZYdVL4Y"
      },
      "source": [
        "## Overview\n",
        "\n",
        "### Protecting Gen AI Applications from Data Leakage\n",
        "Large language models (LLMs) are deep learning models trained on massive datasets of text. LLMs can translate language, summarize text, generate creative writing, generate code, power chatbots and virtual assistants, and complement search engines and recommendation systems.\n",
        "\n",
        "\n",
        "When incorporating your own data into generative AI applications especially via [Model Tuning](https://cloud.google.com/vertex-ai/docs/generative-ai/models/tune-models) it's possible to return a prediction with data from your dataset. In this case many organizations may want to filter LLM responses for sensitive data.\n",
        "\n",
        "\n",
        "By using Sensitive Data Protection(Cloud DLP) we can identify and take corrective action on sensitive data within LLM responses in real time.\n",
        "\n",
        "\n",
        "### Using Sensitive Data Protection(Cloud DLP) to filter LLM Responses\n",
        "\n",
        "[Sensitive Data Protection(Cloud DLP)](https://cloud.google.com/dlp) is a fully managed service designed to discover, classify, and protect your sensitive data, where it resides from databases, text-based content, or even images. It uses a variety of methods to identify sensitive data, including regular expressions, dictionaries, and contextual elements. Once sensitive data is identified, Sensitive Data Protection(Cloud DLP) can take several actions to either classify it, mask it, encrypt it or even delete it.\n",
        "\n",
        "\n",
        "Sensitive Data Protection(Cloud DLP) can be accessed via Cloud Console and used to scan data within Cloud Storage, BigQuery and other Google Cloud services. The following notebook demonstrates using it through the SDK to incorporate Sensitive Data Protection(Cloud DLP) capabilities directly into you Generative AI enabled applications\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQT500QqVPIb"
      },
      "source": [
        "### Objectives\n",
        "\n",
        "In this tutorial, you will learn how to use Sensitive Data Protection(Cloud DLP) API with the Python SDK and explore how to identify and redact sensitive data within a response from PaLM 2 LLM\n",
        "\n",
        "By the end of the notebook, you should be able to understand various configurations of Sensitive Data Protection(Cloud DLP) like `inspect_config`, `deidentify_config`, `item`, and what each variable controls.\n",
        "\n",
        "The steps performed include:\n",
        "\n",
        "- Installing the Python SDKs\n",
        "- Understand a Data Leakage scenario\n",
        "  - Text generation model with `text-bison@001`\n",
        "    - Understanding prompt manipulation to return sensitive data\n",
        "- Understand Data Leakage Mitigations\n",
        "  - Using Sensitive Data Protection(Cloud DLP) with `text-bison@001` responses\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCgai1I3uriY"
      },
      "source": [
        "### Costs\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI Generative AI Studio\n",
        "* Sensitive Data Protection(Cloud DLP)\n",
        "\n",
        "Learn about pricing for [Vertex AI](https://cloud.google.com/vertex-ai/pricing), and\n",
        " [Sensitive Data Protection(Cloud DLP)](https://cloud.google.com/dlp/pricing). Use the [Pricing Calculator](https://cloud.google.com/products/calculator/)\n",
        "to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data governance and security\n",
        "For more information, see the documentation on [Data Governance and Generative AI](https://cloud.google.com/vertex-ai/docs/generative-ai/data-governance) on Google Cloud."
      ],
      "metadata": {
        "id": "Mr5Btx-vwLtr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Responsible AI\n",
        "Large language models (LLMs) can translate language, summarize text, generate creative writing, generate code, power chatbots and virtual assistants, and complement search engines and recommendation systems. At the same time, as an early-stage technology, its evolving capabilities and uses create potential for misapplication, misuse, and unintended or unforeseen consequences. Large language models can generate output that you don't expect, including text that's offensive, insensitive, or factually incorrect.\n",
        "\n",
        "What's more, the incredible versatility of LLMs is also what makes it difficult to predict exactly what kinds of unintended or unforeseen outputs they might produce. Given these risks and complexities, the PaLM API is designed with [Google's AI Principles](https://ai.google/principles/) in mind. However, it is important for developers to understand and test their models to deploy safely and responsibly. To aid developers, the Generative AI Studio has built-in content filtering, and the PaLM API has safety attribute scoring to help customers test Google's safety filters and define confidence thresholds that are right for their use case and business. Please refer to the [Safety filters and attributes](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai#safety_filters_and_attributes) section to learn more.\n",
        "\n",
        "When the PaLM API is integrated into a customer's unique use case and context, additional responsible AI considerations and [PaLM limitations](https://cloud.google.com/vertex-ai/docs/generative-ai/learn/responsible-ai#palm_limitations) may need to be considered. We encourage customers to leverage fairness, interpretability, privacy and security [recommended practices](https://ai.google/responsibilities/responsible-ai-practices/)."
      ],
      "metadata": {
        "id": "0ruKp1yOwN3Z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDU0XJ1xRDlL"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfBCOT7dduP4"
      },
      "outputs": [],
      "source": [
        "#@title Install Vertex AI and Sensitive Data Protection SDK\n",
        "# Install Google Cloud Vertex AI\n",
        "!pip install google-cloud-aiplatform --upgrade --user\n",
        "# Install DLP\n",
        "! pip install google-cloud-dlp\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Restart Runtime\n",
        "After installing the necessary Python SDKs you must restart the python runtime. There are a few options based on environment:\n",
        "\n",
        "**Colab**:\n",
        "1. Click the \"Restart Runtime\" button in the output of the SDK installs\n",
        "2. Click \"Runtime\" on the top toolbar -> Click \"Restart Runtime\"\n",
        "3. Run Colab Runtime Restart Code Block\n",
        "\n",
        "**Vertex AI Workbench**:\n",
        "1. Click \"Kernel\" on the top toolbar -> Click \"Restart Kernel\""
      ],
      "metadata": {
        "id": "9MkbgCJuZa1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Colab Runtime Restart\n",
        "#import os\n",
        "#os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "s-0W3phMbcyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set Project and Location\n",
        "PROJECT_ID = \"[Your Project ID Here]\"  # @param {type:\"string\"}\n",
        "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "icjgvr3Wc3-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fom0ZkMSBW6"
      },
      "source": [
        "### Authenticating your notebook environment\n",
        "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
        "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCaCx6PLSBW6"
      },
      "outputs": [],
      "source": [
        "#from google.colab import auth\n",
        "#auth.authenticate_user(project_id=PROJECT_ID)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Model for Prediction/Generation (text-bison@001)"
      ],
      "metadata": {
        "id": "qNddz_RZTa7C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zjV4alsiVql"
      },
      "outputs": [],
      "source": [
        "from vertexai.preview.language_models import (TextGenerationModel)\n",
        "\n",
        "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding and Mitigating Data Leakage"
      ],
      "metadata": {
        "id": "Ky6waJlQTFTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Threat Use Case: Extract Sensitive Data & Data Leakage Scenario\n",
        "\n",
        "prompt = f\"\"\"Who is the CEO of Google? What is their email?\n",
        "  \"\"\"\n",
        "response = generation_model.predict(prompt)\n",
        "response"
      ],
      "metadata": {
        "id": "J43BzEhlzYML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Inspect and Redact PaLM 2 output with Sensitive Data Protection(Cloud DLP)\n",
        "\n",
        "import google.cloud.dlp  # noqa: F811, E402\n",
        "from typing import List  # noqa: F811, E402\n",
        "\n",
        "def deidentify_with_replace_infotype(\n",
        "    project: str, item: str, info_types: List[str]\n",
        ") -> None:\n",
        "    \"\"\"Uses the Data Loss Prevention API to deidentify sensitive data in a\n",
        "    string by replacing it with the info type.\n",
        "    Args:\n",
        "        project: The Google Cloud project id to use as a parent resource.\n",
        "        item: The string to deidentify (will be treated as text).\n",
        "        info_types: A list of strings representing info types to look for.\n",
        "            A full list of info type categories can be fetched from the API.\n",
        "    Returns:\n",
        "        None; the response from the API is printed to the terminal.\n",
        "    \"\"\"\n",
        "\n",
        "    # Instantiate a client\n",
        "    dlp = google.cloud.dlp_v2.DlpServiceClient()\n",
        "\n",
        "    # Convert the project id into a full resource id.\n",
        "    parent = f\"projects/{PROJECT_ID}\"\n",
        "\n",
        "    # Construct inspect configuration dictionary\n",
        "    inspect_config = {\"info_types\": [{\"name\": info_type} for info_type in info_types]}\n",
        "\n",
        "    # Construct deidentify configuration dictionary\n",
        "    deidentify_config = {\n",
        "        \"info_type_transformations\": {\n",
        "            \"transformations\": [\n",
        "                {\"primitive_transformation\": {\"replace_with_info_type_config\": {}}}\n",
        "            ]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Call the API\n",
        "    response = dlp.deidentify_content(\n",
        "        request={\n",
        "            \"parent\": parent,\n",
        "            \"deidentify_config\": deidentify_config,\n",
        "            \"inspect_config\": inspect_config,\n",
        "            \"item\": {\"value\": item},\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Print out the results.\n",
        "    print(response.item.value)\n",
        "\n",
        "deidentify_with_replace_infotype(PROJECT_ID, response.text, [\"PERSON_NAME\",\"EMAIL_ADDRESS\"])"
      ],
      "metadata": {
        "id": "vINTmTN4D4C9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Ldoma_ZahRc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}